{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 PyTorch\n",
    "import torch\n",
    "\n",
    "# 创建一个张量\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(\"张量 x:\", x)\n",
    "\n",
    "# 张量加法\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "z = x + y\n",
    "print(\"张量 z (x + y):\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 设置数据类型和设备\n",
    "dtype = torch.float  # 张量数据类型为浮点型\n",
    "device = torch.device(\"cpu\")  # 本次计算在 CPU 上进行\n",
    "\n",
    "# 创建并打印两个随机张量 a 和 b\n",
    "a = torch.randn(2, 3, device=device, dtype=dtype)  # 创建一个 2x3 的随机张量\n",
    "b = torch.randn(2, 3, device=device, dtype=dtype)  # 创建另一个 2x3 的随机张量\n",
    "\n",
    "print(\"张量 a:\")\n",
    "print(a)\n",
    "\n",
    "print(\"张量 b:\")\n",
    "print(b)\n",
    "\n",
    "# 逐元素相乘并输出结果\n",
    "print(\"a 和 b 的逐元素乘积:\")\n",
    "print(a * b)\n",
    "\n",
    "# 输出张量 a 所有元素的总和\n",
    "print(\"张量 a 所有元素的总和:\")\n",
    "print(a.sum())\n",
    "\n",
    "# 输出张量 a 中第 2 行第 3 列的元素（注意索引从 0 开始）\n",
    "print(\"张量 a 第 2 行第 3 列的元素:\")\n",
    "print(a[1, 2])\n",
    "\n",
    "# 输出张量 a 中的最大值\n",
    "print(\"张量 a 中的最大值:\")\n",
    "print(a.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.张量\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. NumPy 数组转换为 PyTorch 张量\n",
    "print(\"1. NumPy 转为 PyTorch 张量\")\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"NumPy 数组:\\n\", numpy_array)\n",
    "\n",
    "# 使用 torch.from_numpy() 将 NumPy 数组转换为张量\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(\"转换后的 PyTorch 张量:\\n\", tensor_from_numpy)\n",
    "\n",
    "# 修改 NumPy 数组，观察张量的变化（共享内存）\n",
    "numpy_array[0, 0] = 100\n",
    "print(\"修改后的 NumPy 数组:\\n\", numpy_array)\n",
    "print(\"PyTorch 张量也会同步变化:\\n\", tensor_from_numpy)\n",
    "\n",
    "# 2. PyTorch 张量转换为 NumPy 数组\n",
    "print(\"\\n2. PyTorch 张量转为 NumPy 数组\")\n",
    "tensor = torch.tensor([[7, 8, 9], [10, 11, 12]], dtype=torch.float32)\n",
    "print(\"PyTorch 张量:\\n\", tensor)\n",
    "\n",
    "# 使用 tensor.numpy() 将张量转换为 NumPy 数组\n",
    "numpy_from_tensor = tensor.numpy()\n",
    "print(\"转换后的 NumPy 数组:\\n\", numpy_from_tensor)\n",
    "\n",
    "# 修改张量，观察 NumPy 数组的变化（共享内存）\n",
    "tensor[0, 0] = 77\n",
    "print(\"修改后的 PyTorch 张量:\\n\", tensor)\n",
    "print(\"NumPy 数组也会同步变化:\\n\", numpy_from_tensor)\n",
    "\n",
    "# 3. 注意：不共享内存的情况（需要复制数据）\n",
    "print(\"\\n3. 使用 clone() 保证独立数据\")\n",
    "tensor_independent = torch.tensor([[13, 14, 15], [16, 17, 18]], dtype=torch.float32)\n",
    "numpy_independent = tensor_independent.clone().numpy()  # 使用 clone 复制数据\n",
    "print(\"原始张量:\\n\", tensor_independent)\n",
    "tensor_independent[0, 0] = 0  # 修改张量数据\n",
    "print(\"修改后的张量:\\n\", tensor_independent)\n",
    "print(\"NumPy 数组（不会同步变化）:\\n\", numpy_independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.神经网络基础\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # 定义一个输入层到隐藏层的全连接层\n",
    "        self.fc1 = nn.Linear(2, 2)  # 输入 2 个特征，输出 2 个特征\n",
    "        # 定义一个隐藏层到输出层的全连接层\n",
    "        self.fc2 = nn.Linear(2, 1)  # 输入 2 个特征，输出 1 个预测值\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 前向传播过程\n",
    "        x = torch.relu(self.fc1(x))  # 使用 ReLU 激活函数\n",
    "        x = self.fc2(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleNN()\n",
    "\n",
    "# 打印模型\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.第一个神经网络\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成一些随机数据\n",
    "n_samples = 100\n",
    "data = torch.randn(n_samples, 2)  # 生成 100 个二维数据点\n",
    "labels = (data[:, 0]**2 + data[:, 1]**2 < 1).float().unsqueeze(1)  # 点在圆内为1，圆外为0\n",
    "\n",
    "# 可视化数据\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels.squeeze(), cmap='coolwarm')\n",
    "plt.title(\"Generated Data\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()\n",
    "\n",
    "# 定义前馈神经网络\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # 定义神经网络的层\n",
    "        self.fc1 = nn.Linear(2, 4)  # 输入层有 2 个特征，隐藏层有 4 个神经元\n",
    "        self.fc2 = nn.Linear(4, 1)  # 隐藏层输出到 1 个神经元（用于二分类）\n",
    "        self.sigmoid = nn.Sigmoid()  # 二分类激活函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # 使用 ReLU 激活函数\n",
    "        x = self.sigmoid(self.fc2(x))  # 输出层使用 Sigmoid 激活函数\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = SimpleNN()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()  # 二元交叉熵损失\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  # 使用随机梯度下降优化器\n",
    "\n",
    "# 训练\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # 前向传播\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 每 10 轮打印一次损失\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 可视化决策边界\n",
    "def plot_decision_boundary(model, data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    xx, yy = torch.meshgrid(torch.arange(x_min, x_max, 0.1), torch.arange(y_min, y_max, 0.1), indexing='ij')\n",
    "    grid = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1)], dim=1)\n",
    "    predictions = model(grid).detach().numpy().reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, predictions, levels=[0, 0.5, 1], cmap='coolwarm', alpha=0.7)\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels.squeeze(), cmap='coolwarm', edgecolors='k')\n",
    "    plt.title(\"Decision Boundary\")\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.数据处理与加载\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 自定义数据集类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        \"\"\"\n",
    "        初始化数据集，X_data 和 Y_data 是两个列表或数组\n",
    "        X_data: 输入特征\n",
    "        Y_data: 目标标签\n",
    "        \"\"\"\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集的大小\"\"\"\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"返回指定索引的数据\"\"\"\n",
    "        x = torch.tensor(self.X_data[idx], dtype=torch.float32)  # 转换为 Tensor\n",
    "        y = torch.tensor(self.Y_data[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# 示例数据\n",
    "X_data = [[1, 2], [3, 4], [5, 6], [7, 8]]  # 输入特征\n",
    "Y_data = [1, 0, 1, 0]  # 目标标签\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = MyDataset(X_data, Y_data)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 创建 DataLoader 实例，batch_size 设置每次加载的样本数量\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 打印加载的数据\n",
    "for epoch in range(1):\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        print(f'Batch {batch_idx + 1}:')\n",
    "        print(f'Inputs: {inputs}')\n",
    "        print(f'Labels: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.线性回归\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "# 随机种子，确保每次运行结果一致\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 生成训练数据\n",
    "X = torch.randn(100, 2)  # 100 个样本，每个样本 2 个特征\n",
    "true_w = torch.tensor([2.0, 3.0])  # 假设真实权重\n",
    "true_b = 4.0  # 偏置项\n",
    "Y = X @ true_w + true_b + torch.randn(100) * 0.1  # 加入一些噪声\n",
    "\n",
    "# 打印部分数据\n",
    "print(X[:5])\n",
    "print(Y[:5])\n",
    "\n",
    "# 定义线性回归模型\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        # 定义一个线性层，输入为2个特征，输出为1个预测值\n",
    "        self.linear = nn.Linear(2, 1)  # 输入维度2，输出维度1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # 前向传播，返回预测结果\n",
    "\n",
    "# 创建模型实例\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# 损失函数（均方误差）\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 优化器（使用 SGD 或 Adam）\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # 学习率设置为0.01\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 1000  # 训练 1000 轮\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "\n",
    "    # 前向传播\n",
    "    predictions = model(X)  # 模型输出预测值\n",
    "    loss = criterion(predictions.squeeze(), Y)  # 计算损失（注意预测值需要压缩为1D）\n",
    "\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()  # 清空之前的梯度\n",
    "    loss.backward()  # 计算梯度\n",
    "    optimizer.step()  # 更新模型参数\n",
    "\n",
    "    # 打印损失\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/1000], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # 查看训练后的权重和偏置\n",
    "print(f'Predicted weight: {model.linear.weight.data.numpy()}')\n",
    "print(f'Predicted bias: {model.linear.bias.data.numpy()}')\n",
    "\n",
    "# 在新数据上做预测\n",
    "with torch.no_grad():  # 评估时不需要计算梯度\n",
    "    predictions = model(X)\n",
    "\n",
    "# 可视化预测与实际值\n",
    "plt.scatter(X[:, 0], Y, color='blue', label='True values')\n",
    "plt.scatter(X[:, 0], predictions, color='red', label='Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
